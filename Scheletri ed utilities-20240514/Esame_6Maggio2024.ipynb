{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e97ec2-857d-44c0-8b7f-c9b2c436362e",
   "metadata": {},
   "source": [
    "## Esame di Metodi Numerici 6 Maggio 2024 \n",
    "\n",
    "## Esercizo 1\n",
    "- Si consideri il sistema lineare Ax=b, con A matrice e b termine noto memorizzati nel file ``'test_14_09_2023.mat'``.  Risolvere il sistema confrontando almeno due tra i metodi  visti  per utilizzare per risolvere il sistema lineare con tale matrice dei coefficienti. Confrontare i risultati dei vari metodi, e giustificare i loro comportamento utilizzando i risultati teorici visti a lezione.\n",
    "- \n",
    "Per la lettura dei dati procedere nel seguente modo:\n",
    "\n",
    "``from scipy.io import loadmat``\n",
    "\n",
    "``import numpy as np``\n",
    "\n",
    "``dati = loadmat('test_06_05_2024.mat')``\n",
    "\n",
    "``A=dati[\"A\"] ``\n",
    "\n",
    "``A=A.astype(float)``\n",
    "\n",
    "`` b=dati[\"b\"] ``\n",
    "\n",
    "`` b=b.astype(float)``\n",
    "\n",
    "\n",
    "                                       [10 punti]\n",
    "                                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943487e9-8cbc-4314-be52-8cffacd79959",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 ,  400\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dati = loadmat('test_06_05_2024.mat')\n",
    "A=dati[\"A\"] \n",
    "A=A.astype(float)\n",
    "b=dati[\"b\"]\n",
    "b=b.astype(float)\n",
    "m, n = A.shape\n",
    "print(m, \", \", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebf8497c-949e-46d9-bca4-027aac703f77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2449999999999999 %\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(A)/(n*m) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b342c6a-f58d-46bb-a2c3-098b6d64ab53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice simmetrica\n",
      "Matrice definita positiva? True\n"
     ]
    }
   ],
   "source": [
    "if np.all(A==A.T) == 0 :\n",
    "    print(\"Matrice non simmetrica\")\n",
    "else :\n",
    "    print(\"Matrice simmetrica\")\n",
    "    autoval = np.linalg.eigvals(A)\n",
    "    print(f\"Matrice definita positiva? {np.all(autoval > 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d568535-ea0f-48bd-9b13-6c0dae12c192",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conjugate_gradient(A,b,x0,itmax,tol):\n",
    "    n,m=A.shape\n",
    "    if n!=m:\n",
    "        print(\"Matrice non quadrata\")\n",
    "        return [],[]\n",
    "    \n",
    "    \n",
    "   # inizializzare le variabili necessarie\n",
    "    x = x0\n",
    "    \n",
    "    r = A@x-b\n",
    "    p = -r\n",
    "    it = 0\n",
    "    nb=np.linalg.norm(b)\n",
    "    errore=np.linalg.norm(r)/nb\n",
    "    vec_sol=[]\n",
    "    vec_sol.append(x0)\n",
    "    vet_r=[]\n",
    "    vet_r.append(errore)\n",
    "# utilizzare il metodo del gradiente coniugato per calcolare la soluzione\n",
    "    while errore >= tol and it< itmax:\n",
    "        it=it+1\n",
    "        Ap = A.dot(p)\n",
    "        alpha = - r.T@p / p.T@Ap\n",
    "        x = x + alpha*p\n",
    "        vec_sol.append(x)\n",
    "        rtr_old=r.T@r\n",
    "        r=r+alpha*Ap\n",
    "        gamma = r.T@r / rtr_old\n",
    "        errore=np.linalg.norm(r)/nb\n",
    "        vet_r.append(errore)\n",
    "        p =  -r + gamma*p\n",
    "   \n",
    "    \n",
    "    return x,vet_r,vec_sol,it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb288cc-5b92-4401-b3b8-9870b22e94cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pietro.pasini4\\AppData\\Local\\Temp\\ipykernel_18876\\3252812215.py:29: RuntimeWarning: overflow encountered in matmul\n",
      "  gamma = r.T@r / rtr_old\n",
      "C:\\Users\\pietro.pasini4\\AppData\\Local\\Temp\\ipykernel_18876\\3252812215.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  alpha = - r.T@p / p.T@Ap\n",
      "C:\\Users\\pietro.pasini4\\AppData\\Local\\Temp\\ipykernel_18876\\3252812215.py:27: RuntimeWarning: overflow encountered in matmul\n",
      "  rtr_old=r.T@r\n"
     ]
    }
   ],
   "source": [
    "x,vet_r,vec_sol,it = conjugate_gradient(A, b, np.zeros_like(b), 200, 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c0d44a-0d01-44c1-b47f-9a155608f40b",
   "metadata": {},
   "source": [
    "- Data la matrice \n",
    "$$A=\\left[\n",
    "\\begin{array}{cccc}\n",
    "1 & 2 & 3 & 4\\\\\n",
    "2 & -4 & 6 & 8\\\\\n",
    "-1 & -2 & -3 & -1\\\\\n",
    "5 & 7 & 0 & 1\n",
    "\\end{array}\n",
    "\\right ],$$\n",
    "Richiamare le ipotesi sotto cui esiste la fattorizzazione di Gauss senza pivoting e scrivere un codice per  verificarle.\n",
    "\n",
    "                                                [2 punti]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbda924-2d3b-4357-bf34-cb936d3a4a87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Esercizio 2\n",
    "Scrivere uno script che calcoli il polinomio interpolante un insieme di punti $P_i =(x_i, y_i)$ $i = 0, ..., n $ nella forma di Lagrange, $n=5,10,15,18$\n",
    "\n",
    "- nodi $x_i$, punti equidistanti in un intervallo $[a, b]$,\n",
    "- nodi $x_i$, zeri dei polinomi di Chebyshev nell'intervallo $[a, b]$, ossia\n",
    "$$\n",
    "x_i = \\frac{(a + b)}{2}+\\frac{(b-a)}{2} \\, \\cos \\left(\n",
    "\\frac{(2i+1)\\pi}{2(n + 1)}\n",
    "\\right), \\quad  i =0, ..., n \n",
    "$$\n",
    " \n",
    "  e $y_i = f(x_i)$ ottenuti dalla valutazione nei punti $x_i$ della funzione test   $f: \\ [a, b] \\rightarrow {\\mathbb R}$. \n",
    "  - $f(x) = 1/(1+25*x^2)$,  $ \\quad x \\in [-1, 1]$ (funzione di Runge).\n",
    "  \n",
    "                                          [6] punti\n",
    "\n",
    "- Calcolare l'errore di interpolazione $r(x) =  f(x)-pe(x) $,\n",
    "tra la funzione test $f(x)$ e il polinomio di interpolazione $pe(x)$ calcolato a partire da nodi equdisitanti.\n",
    "                                        [1] punto\n",
    "                                        \n",
    "Visualizzare il grafico di $f(x)$ e $pe(x)$, ed il grafico di $|r(x)|$ per ogni valore $n=5,10,15,18$ \n",
    "\n",
    "                                        [1] punto\n",
    "                                        \n",
    "Calcolare l'errore di interpolazione $r(x) =  f(x)-pc(x) $,\n",
    "tra la funzione test $f(x)$ e il polinomio di interpolazione $p(x)$ calcolato a partire da nodi di Chebichev.\n",
    "\n",
    "                                      [1] punto\n",
    "                                            \n",
    "Visualizzare il grafico di $f(x)$ e $pc(x)$, ed il grafico di $|r(x)|$. \n",
    "\n",
    "                                       [1] punto\n",
    "\n",
    "Cosa si osserva? Cosa accade all'aumentare del grado $n$ di $p(x)$? Scrivere la formula dell'errore che si compie quando al posto della funzione che ha generato i dati si considera il polinomio interpolatore di grado n e commentarla.\n",
    "                                         \n",
    "                                         [3 punti]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4239d5c-a24b-432f-9903-e5d5e67f0669",
   "metadata": {},
   "source": [
    "**Domanda AI**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5721a2f9-b321-4904-a015-98e1ff91f89c",
   "metadata": {},
   "source": [
    "- Descrivere gli elementi caratterizzanti di un MultiLayer Perceptron (MLP).( Com'Ã¨ fatto un neurone artificiale, a caso servono le funzioni di attivazione, come sono organizzati i neuroni. Varie tipologie di reti MLP)  ed accennare in cosa consiste la fase di forward propagation e la fase di backward propagation. **Punti: 1**\n",
    "\n",
    "- Ottimizzazione della loss function per il training di una rete neurale per il task di regressione: Metodo di discesa del gradiente, metodo stocastico del gradiente, metodo del gradiente minibatch.  **Punti 1**  \n",
    " - Non convessitÃ  della loss-function - come non rimanere bloccati in un monimo locale? Metodo del gradiente con momentum. **Punti 2**\n",
    "- Learning rate scheduling: step decay, decadimento esponenziale, decadimento dipendente dal tempo. **Punti 1**\n",
    " - Learning rate adattivo: Adagrad, RMSProp, Adadelta, Adam. **Punti 2**\n",
    " \n",
    " **Totale:  7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95c228-c321-4608-9f05-a6364a46465c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
